# 模型评估与选择
 
## 经验误差与过拟合

通常我们把分类错误的样本数占样本总数的比例称为"错误率"(error rate) ，即如果在 m 个样本中有 α 个样本分类错误，则错误率 E = α/m; 相应的，1一α/m 称为"精度" (accuracy)，即"精度=1一错误率"。

更一般地，我们把学习器的实际预测输出与样本的真实输出之间的差异称为"误差" (error), 学习器在训练集上的误差称为"训练误差" (training error)或"经验误差" (empirical error) ，在新样本上的误差称为"泛化误差" (generalization error)。

显然，我们希望得到泛化误差小的学习器。然而，我们事先并不知道新样本是什么样，实际能做的是努力使经验误差最小化。在很多情况下，我们可以学得一个经验误差很小、在训练集上表现很好的学习器，例如甚至对所有训练样本都分类正确，即分类错误率为零，分类精度为 100%，但这是不是我们想要 的学习器呢?遗憾的是，这样的学习器在多数情况下都不好。

我们实际希望的，是在新样本上能表现得很好的学习器。为了达到这个目的，应该从训练样本中尽可能学出适用于所有潜在样本的"普遍规律"，这样才能在遇到新样本时做出正确的判别。然而，当学习器把训练样本学得"太好"了的时候，很可能巳经把训练样本自身的一些特点当作了所有潜在样本都会具有的一般性质，这样就会导致泛化性能下降这种现象在机器学习中称为 "过拟合" (overfitting)。 与"过拟合"相对的是"欠拟合" (underfitting)，这是指对训练样本的一般性质尚未学好。

![拟合](/images/zzh04.png)

有多种因素可能导致过拟合，其中最常见的情况是由于学习能力过于强大，以至于把训练样本所包含的不太一般的特性都学到了，而欠拟合则通常是由于学习能力低下而造成的。

欠拟合比较容易克服，例如在决策树学习中扩展分支、在神经网络学习中增加训练轮数等，而过拟合则很麻烦。在后面的学习中我们将看到，过拟合是机器学习面临的关键障碍，各类学习算法都必然带有一些针对过拟合的措施；然而必须认识到，过拟合是无法彻底避免的，我们所能做的只是"缓解"，或者说减小其风险。

关于这一点，可大致这样理解：机器学习面临的问题通常是 NP 难甚至更难，而有效的学习算法必然是在多项式时间内运行完成，若可彻底避免过拟合， 则通过经验误差最小化就能获最优解，这就意味着我们构造性地证明了 "P=NP" ;因此，只要相信 "P=NP" ，过拟合就不可避免。

在现实任务中，我们往往有多种学习算法可供选择，甚至对同-个学习算法，当使用不同的参数配置时，也会产生不同的模型。那么，我们该选用哪-个 学习算法、使用哪一种参数配置呢?这就是机器学习中的"模型选择" (model selection) 问题。理想的解决方案当然是对候选模型的泛化误差进行评估，然后选择泛化误差最小的那个模型。然而如上面所讨论的，我们无法直接获得泛化误差，而训练误差又由于过拟合现象的存在而不适合作为标准，那么，在现实中 如何进行模型评估与选择呢?

## 评估方法

